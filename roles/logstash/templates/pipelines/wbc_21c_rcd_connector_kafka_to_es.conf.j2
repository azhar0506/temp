# ====================================
# Passes data from Kafka topic consuming RCD Connector monitoring events to the relevnat Elastic Search index
# ====================================


input {
  {%+ for input in item.kafka_inputs %}
  kafka {
    type              => "rcd"
    bootstrap_servers => "{{ input.kafka_bootstrap_servers | default("default") }}"
    group_id          => "{{ input.pipeline_group_id       | default("default") }}"
    client_id         => "{{ input.pipeline_client_id      | default("default") }}"
    topics            => {{  input.kafka_topics            | default('["wbc_default"]') }}

    consumer_threads           => {{ logstash_pipeline_consumer_threads | default(2) }}
    sasl_kerberos_service_name => "kafka"
    security_protocol          => "SASL_PLAINTEXT"
    jaas_path                  => "{{ logstash_jaas_path | default("/usr/share/config/jaas.conf") }}"
    kerberos_config            => "{{ logstash_kerberos_config_path | default("/usr/share/config/default.conf") }}"
    auto_offset_reset          => "latest"

    client_dns_lookup => "use_all_dns_ips"
  }
  {% endfor %}
}

filter {
  json {
    source => "message"
  }
  date {
    match  => ["time_event_occured", "UNIX_MS"]
    target => "time_event_occured"
  }
  ruby {
    code => "event.set('time_to_arrive', (event.get('@timestamp') - event.get('time_event_occured')).to_f)"
  }
  mutate {
    remove_field => ["@version", "path", "host", "message"]
  }
}

output {
  elasticsearch {
    hosts    => {{ logstash_output_elasticsearch_hosts | default("") }}
    index    => "wbc-rcd-connector-monitoring-events-%{+YYYY.MM.dd}"
    user     => "{{ logstash_output_elasticsearch_username | default("elastic") }}"
    password => "{{ logstash_output_elasticsearch_password | default("no_password") }}"

    ssl_enabled                 => true
    ssl_certificate_authorities => "{{ logstash_output_elasticsearch_ssl_certificate_authority | default("/usr/share/logstash/ca.crt") }}"
  }
}
